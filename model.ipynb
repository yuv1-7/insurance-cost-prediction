{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ef95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d05e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data():\n",
    "    \"\"\"Load the insurance dataset and perform initial exploration\"\"\"\n",
    "    print(\"=== STEP 1: DATA COLLECTION & UNDERSTANDING ===\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('insurance.csv')\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nDataset info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df.duplicated().sum())\n",
    "    if (df.duplicated().sum()>0):\n",
    "        df = df.drop_duplicates(keep='first')\n",
    "        print(\"removing duplicates\")\n",
    "        print(df.duplicated().sum())\n",
    "\n",
    "    print(\"\\nStatistical summary:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nCategorical variables unique values:\")\n",
    "    categorical_cols = ['sex', 'smoker', 'region']\n",
    "    for col in categorical_cols:\n",
    "        print(f\"{col}: {df[col].unique()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df):\n",
    "    \"\"\"Create visualizations for data exploration\"\"\"\n",
    "    print(\"\\n=== DATA VISUALIZATION ===\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. Charges distribution\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.hist(df['charges'], bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title('Distribution of Insurance Charges')\n",
    "    plt.xlabel('Charges')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    # 2. Charges vs Age\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.scatter(df['age'], df['charges'], alpha=0.6)\n",
    "    plt.title('Charges vs Age')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Charges')\n",
    "    \n",
    "    # 3. Charges vs BMI\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.scatter(df['bmi'], df['charges'], alpha=0.6)\n",
    "    plt.title('Charges vs BMI')\n",
    "    plt.xlabel('BMI')\n",
    "    plt.ylabel('Charges')\n",
    "    \n",
    "    # 4. Charges by Smoker status\n",
    "    plt.subplot(2, 3, 4)\n",
    "    df.boxplot(column='charges', by='smoker', ax=plt.gca())\n",
    "    plt.title('Charges by Smoker Status')\n",
    "    plt.suptitle('')  # Remove the automatic title\n",
    "    \n",
    "    # 5. Charges by Sex\n",
    "    plt.subplot(2, 3, 5)\n",
    "    df.boxplot(column='charges', by='sex', ax=plt.gca())\n",
    "    plt.title('Charges by Sex')\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # 6. Correlation heatmap\n",
    "    plt.subplot(2, 3, 6)\n",
    "    # Convert categorical to numerical for correlation\n",
    "    df_corr = df.copy()\n",
    "    df_corr['sex'] = df_corr['sex'].map({'male': 1, 'female': 0})\n",
    "    df_corr['smoker'] = df_corr['smoker'].map({'yes': 1, 'no': 0})\n",
    "    df_corr = pd.get_dummies(df_corr, columns=['region'])\n",
    "    \n",
    "    corr_matrix = df_corr.corr()\n",
    "    sns.heatmap(corr_matrix[['charges']].sort_values('charges', ascending=False), \n",
    "                annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Features Correlation with Charges')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data for machine learning\"\"\"\n",
    "    print(\"\\n=== STEP 2: DATA PREPROCESSING ===\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('charges', axis=1)\n",
    "    y = df['charges']\n",
    "    \n",
    "    # Define preprocessing for numerical and categorical features\n",
    "    numerical_features = ['age', 'bmi', 'children']\n",
    "    categorical_features = ['sex', 'smoker', 'region']\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Test set size: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ea7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    \"\"\"Build and compare different models\"\"\"\n",
    "    print(\"\\n=== STEP 3: MODEL BUILDING ===\")\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    best_model = None\n",
    "    best_score = float('-inf')\n",
    "    best_pipeline = None\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'pipeline': pipeline\n",
    "        }\n",
    "        \n",
    "        print(f\"MSE: {mse:.2f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        \n",
    "        if r2 > best_score:\n",
    "            best_score = r2\n",
    "            best_model = name\n",
    "            best_pipeline = pipeline\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model} with R² Score: {best_score:.4f}\")\n",
    "    \n",
    "    return results, best_pipeline, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a05e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X_train, y_train, preprocessor):\n",
    "    \"\"\"Perform hyperparameter tuning for Random Forest\"\"\"\n",
    "    print(\"\\n=== HYPERPARAMETER TUNING ===\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20],\n",
    "        'regressor__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the best model and create visualizations\"\"\"\n",
    "    print(\"\\n=== STEP 4: MODEL EVALUATION ===\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Final Model Performance:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Charges')\n",
    "    plt.ylabel('Predicted Charges')\n",
    "    plt.title('Actual vs Predicted Charges')\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Charges')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename='insurance_cost_model.pkl'):\n",
    "    \"\"\"Save the trained model\"\"\"\n",
    "    print(f\"\\n=== STEP 5: MODEL SAVING ===\")\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_insurance_cost(model, age, sex, bmi, children, smoker, region):\n",
    "    \"\"\"Predict insurance cost for new data\"\"\"\n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame({\n",
    "        'age': [age],\n",
    "        'sex': [sex],\n",
    "        'bmi': [bmi],\n",
    "        'children': [children],\n",
    "        'smoker': [smoker],\n",
    "        'region': [region]\n",
    "    })\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    return round(prediction, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main function to run the complete pipeline\"\"\"\n",
    "print(\"MEDICAL INSURANCE COST PREDICTOR\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Data Collection & Understanding\n",
    "df = load_and_explore_data()\n",
    "visualize_data(df)\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "X_train, X_test, y_train, y_test, preprocessor = preprocess_data(df)\n",
    "\n",
    "# Step 3: Model Building\n",
    "results, best_pipeline, best_model_name = build_models(\n",
    "    X_train, X_test, y_train, y_test, preprocessor\n",
    ")\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "tuned_model = hyperparameter_tuning(X_train, y_train, preprocessor)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "mse, rmse, r2 = evaluate_model(tuned_model, X_test, y_test)\n",
    "\n",
    "# Step 5: Model Saving\n",
    "save_model(tuned_model)\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING COMPLETE ===\")\n",
    "print(\"You can now use the model for predictions!\")\n",
    "\n",
    "# Example prediction\n",
    "print(\"\\n=== EXAMPLE PREDICTION ===\")\n",
    "sample_prediction = predict_insurance_cost(\n",
    "    tuned_model, \n",
    "    age=25, \n",
    "    sex='male', \n",
    "    bmi=26.2, \n",
    "    children=0, \n",
    "    smoker='no', \n",
    "    region='southwest'\n",
    ")\n",
    "print(f\"Predicted insurance cost for a 25-year-old non-smoking male: ${sample_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
